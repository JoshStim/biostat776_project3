---
title: 'Statistical Computing: Project 3'
author: "Josh Stim"
date: "2023-10-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exploring album sales and sentiment of lyrics from Beyoncé and Taylor Swift {.tabset .tabset-fade}

## Part 0. Setting up

Load relevant R packages
```{r}
library(here)
library(tidyverse)
library(tidytext)
library(wordcloud)
library(textdata)
```

Get data from tidytuesday github and store locally. Load the datasets and make copy for modification.
```{r, fig.show = 'hold', results = 'hold', message = FALSE}
if (!file.exists(here("data", "b_lyrics.RDS"))) {
    b_lyrics <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/beyonce_lyrics.csv")
    ts_lyrics <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/taylor_swift_lyrics.csv")
    sales <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/sales.csv")

    # save the files to RDS objects
    saveRDS(b_lyrics, file = here("data", "b_lyrics.RDS"))
    saveRDS(ts_lyrics, file = here("data", "ts_lyrics.RDS"))
    saveRDS(sales, file = here("data", "sales.RDS"))
}

b_lyrics.raw <- readRDS(here("data", "b_lyrics.RDS"))
ts_lyrics.raw <- readRDS(here("data", "ts_lyrics.RDS")) %>%
  mutate(Album = str_to_title(Album))
sales.raw <- readRDS(here("data", "sales.RDS"))
sales.mod <- sales.raw
```

## Part 1. Explore album sales

In this section, the goal is to explore the sales of studio albums from Beyoncé and Taylor Swift.

#### Notes

-   In each of the subsections below that ask you to create a plot, you must create a title, subtitle, x-axis label, and y-axis label with units where applicable. For example, if your axis says “sales” as an axis label, change it to “sales (in millions)”.

### a. Data wrangling

1.    Use lubridate to create a column called released that is a Date class. However, to be able to do this, you first need to use stringr to search for pattern that matches things like this “(US)[51]” in a string like this “September 1, 2006 (US)[51]” and removes them. (Note: to get full credit, you must create the regular expression).

2.    Use forcats to create a factor called country (Note: you may need to collapse some factor levels).

3.    Transform the sales into a unit that is album sales in millions of dollars.

4.    Keep only album sales from the UK, the US or the World.

5.    Auto print your final wrangled tibble data frame.

```{r, fig.show = 'hold', results = 'hold', message = FALSE}
################################################################################
# 1. Convert sales$released to variable of type Date
################################################################################
names(sales.mod)[2] <- "Album"              # change 'title' column name to 'Album'

sales.mod$released <- 
  str_replace(sales.raw$released, "( |)\\(U(K|S)\\)\\[[0-9]{2}\\]$", "") %>%
  mdy()

################################################################################
# 2. Make sales$country into a factor variable
################################################################################
sales.mod$country <- 
  factor(sales.raw$country) %>%
  fct_collapse(
    WW = c("WW", "World"),
    FRA = c("FRA","FR")
  )

################################################################################
# 3 & 4. Transform sales$sales to "millions of dollars". Only look at album 
# sales from US, UK, and World
################################################################################
sales.mod$sales <- sales.raw$sales / (10 ** 6)
sales.mod.subset <- filter(sales.mod, country %in% c("US", "UK", "WW"))

################################################################################
# 5. Auto print final wrangled tibble data frame.
################################################################################
sales.mod.subset
```

### b. More data wrangling

1.    Keep only album sales from the US.

2.    Create a new column called years_since_release corresponding to the number of years since the release of each album from Beyoncé and Taylor Swift. This should be a whole number and you should round down to “14” if you get a non-whole number like “14.12” years. (Hint: you may find the interval() function from lubridate helpful here, but this not the only way to do this.)

3.    Calculate the most recent, oldest, and the median years since albums were released for both Beyoncé and Taylor Swift.

** Josh: The newest, median, and oldest Beyoncé albums were released 7, 13, and 20 years ago, respectively. The newest, median, and oldest Taylor Swift albums were released 4, 11, and 16 years ago. **
```{r, fig.show = 'hold', results = 'hold', message = FALSE}
sales.mod.subset %>%
  filter(country == "US") %>%
  mutate(years_since_release = year(as.period(interval(released, today())))) %>%
  group_by(artist) %>%
  summarize(newest.years_since_release = min(years_since_release),
            oldest.years_since_release = max(years_since_release),
            median.years_since_release = median(years_since_release))

```

### c. Album sales share by country: Percent stacked barchart

Using the wrangled data from Part 1A:

1.    Calculate the total album sales for each artist and for each country (only sales from the UK, US, and World).

2.    Using the total album sales, create a percent stacked barchart using ggplot2 of the percentage of sales of studio albums (in millions) along the y-axis for the two artists along the x-axis colored by the country.

```{r, fig.show = 'hold', results = 'hold', message = FALSE}
sales.mod.subset %>%
  group_by(artist, country) %>%
  summarize(total.sales = sum(sales)) %>%
  ggplot(aes(x = artist, y = total.sales, fill = country)) +
  geom_bar(position = "fill", stat = "identity") +
  labs(title = "Where do Taylor Swift and Beyoncé Sell the Most Albums?",
       subtitle = "Both artists experience the most sales in the World Wide market. \nCompared to Beyoncé, a greater proportion of Taylor Swift albums are sold in the US.",
       x = "Artist",
       y = "Proportion of album sales",
       caption = "Created by Josh Stim using ggplot2") +
  theme_bw() +
  theme(text = element_text(family = "Times"),
        plot.title = element_text(size = 18))
```

### d. Album sales by album: Horizontal bar chart

Using the wrangled data from Part 1A, use ggplot2 to create a bar plot for the sales of studio albums (in millions) along the x-axis for each of the album titles along the y-axis.

#### Note.

-   You only need to consider the global World sales (you can ignore US and UK sales for this part).

-   The title of the album must be clearly readable along the y-axis.

-   Each bar should be colored by which artist made that album.

-   The bars should be ordered from albums with the most sales (top) to the least sales (bottom) (Note: you must use functions from forcats for this step).

```{r, fig.show = 'hold', results = 'hold', message = FALSE}
sales.mod.subset %>%
  filter(country == "WW") %>%
  arrange(sales) %>%
  ggplot(aes(x = fct_inorder(Album), y = sales, fill = artist)) +
  geom_bar(stat = "identity") +
  labs(x = "Album Title",
       y = "Sales (in Million USD)") +
  coord_flip() + 
  labs(title = "Albums, Ranked by World Wide Sales",
       subtitle = "Taylor Swift's 'Fearless' experienced the highest sales out of all analyzed albums.",
       caption = "Created by Josh Stim using ggplot2")+
  theme_bw() +
  theme(text = element_text(family = "Times"),
        plot.title = element_text(size = 18))
```

### e. Visualizing album sales across time: Scatter Plot

Using the wrangled data from Part 1A, use ggplot2 to create a scatter plot of sales of studio albums (in millions) along the y-axis by the released date for each album along the x-axis.

#### Note:

-   The points should be colored by the artist.

-   There should be three scatter plots (one for UK, US and world sales) faceted by rows.

```{r, fig.show = 'hold', results = 'hold', message = FALSE}
sales.mod.subset %>%
  ggplot(aes(x = released, y = sales, color = artist)) +
  geom_hline(yintercept = 0) +
  geom_point() +
  facet_wrap(~country, nrow = 3) +
  labs(title = "Beyoncé & Taylor Swift: Album sales across time and place",
       subtitle = "Older albums experience more sales than newer ones. Taylor Swift albums generally have \nmore sales compared Beyoncé albums relased at a similar time.",
       x = "Release date",
       y = "Sales (in Million USD)",
       caption = "Created by Josh Stim using ggplot2") +
  theme_bw() +
  theme(text = element_text(family = "Times"),
        plot.title = element_text(size = 18))
```

## Part 2. Exploring Sentiment of Lyrics

### a. Using `ts_lyrics`, create a new column called `line` with one line containing the character string for each line of Taylor Swift’s songs. 
-   How many lines in Taylor Swift’s lyrics contain the word “hello”? For full credit, show all the rows in `ts_lyrics` that have “hello” in the line column and report how many rows there are in total.

-   How many lines in Taylor Swift’s lyrics contain the word “goodbye”? For full credit, show all the rows in `ts_lyrics` that have “goodbye” in the line column and report how many rows there are in total.

```{r, fig.show = 'hold', message = FALSE}
################################################################################
# Flatten ts_lyrics by separating Lyrics into lines
################################################################################
ts_lyrics.mod.lines <- ts_lyrics.raw %>%
  unnest_tokens(
    output = line,
    input = Lyrics,
    token = "lines"
  )
################################################################################
# Report lines that contain the word "hello"
################################################################################
ts_lyrics.mod.lines %>%
  filter(str_detect(line, "hello"))

################################################################################
# Report lines that contain the word "goodbye"
################################################################################
ts_lyrics.mod.lines %>%
  filter(str_detect(line, "goodbye"))
```

### b. Repeat the same analysis for b_lyrics as described in Part 2A.

```{r, fig.show = 'hold', message = FALSE}
b_lyrics.raw %>%
    filter(str_detect(line, "hello"))

b_lyrics.raw %>%
  filter(str_detect(line, "goodbye"))
```

### c. Sentiment analysis of Beyoncé lyrics

Using the `b_lyrics` dataset,

1.    Tokenize each lyrical line by words.

2.    Remove the “stopwords”.

3.    Calculate the total number for each word in the lyrics.

4.    Using the “bing” sentiment lexicon, add a column to the summarized data frame adding the “bing” sentiment lexicon.

5.    Sort the rows from most frequent to least frequent words.

6.    Only keep the top 25 most frequent words.

7.    Auto print the wrangled tibble data frame.

8.    Use `ggplot2` to create a bar plot with the top words on the y-axis and the frequency of each word on the x-axis. Color each bar by the sentiment of each word from the “bing” sentiment lexicon. Bars should be ordered from most frequent on the top to least frequent on the bottom of the plot.

9.    Create a word cloud of the top 25 most frequent words.

```{r, fig.show = 'hold', results = 'hold', message = FALSE}
################################################################################
# Tokenize b_lyrics by words
################################################################################
b_lyrics.mod.words <- b_lyrics.raw %>%
    unnest_tokens(
    output = word,
    input = line,
    token = "words"
  ) %>%
  anti_join(stop_words)

################################################################################
# Create summary of b_lyrics that includes word frequency and sentiment scores
################################################################################
b_lyrics.summary <- b_lyrics.mod.words %>%
  count(word, sort = TRUE) %>%
  inner_join(get_sentiments("bing")) %>%
  head(n = 25L)

b_lyrics.summary
  
################################################################################
# Plot Top 25 Words ordered by frequency and colored by sentiment valence
################################################################################
b_lyrics.summary %>%
  ggplot(aes(x = fct_rev(fct_inorder(word)), y = n, fill = sentiment)) +
  geom_bar(stat = "identity") +
  labs(title = "Beyonce Sentiment Analysis: Top 25 Words",
       subtitle = "'Love' is the most commonly used word across all Beyoncé lyrics in the bing sentiment\nlexicon. 12 of her top 25 words are classified as having negative valence.",
       x = "Word",
       y = "Count") +
  coord_flip() +
  theme_bw() +
  theme(text = element_text(family = "Times"),
        plot.title = element_text(size = 18))

################################################################################
# Plot word cloud of top 25 words
################################################################################
b_lyrics.summary %>%
  with(wordcloud(word, n))
```

### d. Repeat the same analysis as above in Part 2C, but for `ts_lyrics`.

```{r, fig.show = 'hold', results = 'hold', message = FALSE}
################################################################################
# Tokenize ts_lyrics by words
################################################################################
ts_lyrics.mod.words <- ts_lyrics.mod.lines %>%
    unnest_tokens(
    output = word,
    input = line,
    token = "words"
  ) %>%
  anti_join(stop_words)

################################################################################
# Create summary of b_lyrics that includes word frequency and sentiment scores
################################################################################
ts_lyrics.summary <- ts_lyrics.mod.words %>%
  count(word, sort = TRUE) %>%
  inner_join(get_sentiments("bing")) %>%
  head(n = 25L)

ts_lyrics.summary
  
################################################################################
# Plot Top 25 Words ordered by frequency and colored by sentiment valence
################################################################################
ts_lyrics.summary %>%
  ggplot(aes(x = fct_rev(fct_inorder(word)), y = n, fill = sentiment)) +
  geom_bar(stat = "identity") +
  labs(title = "Taylor Swift Sentiment Analysis: Top 25 Words",
       subtitle = "'Love' is the most commonly used word across all Taylor Swift lyrics in the bing sentiment\nlexicon. 15 of her top 25 words are classified as having negative valence.",
       x = "Word",
       y = "Count",
       caption = "Created by Josh Stim using ggplot2") +
  coord_flip() +
  theme_bw() +
  theme(text = element_text(family = "Times"),
        plot.title = element_text(size = 18))

################################################################################
# Plot word cloud of top 25 words
################################################################################
ts_lyrics.summary %>%
  with(wordcloud(word, n))
```

### e. Mean lyric sentiment by Taylor Swift album

1.    Tokenize each lyrical line by words.

2.    Remove the “stopwords”.

3.    Calculate the total number for each word in the lyrics for each Album.

4.    Using the “afinn” sentiment lexicon, add a column to the summarized data frame adding the “afinn” sentiment lexicon.

5.    Calculate the average sentiment score for each Album.

6.    Auto print the wrangled tibble data frame.

7.    Join the wrangled data frame from Part 1A (album sales in millions) filtered down to US sales with the wrangled data frame from #6 above (average sentiment score for each album).

8.    Using ggplot2, create a scatter plot of the average sentiment score for each album (y-axis) and the album release data along the x-axis. Make the size of each point the album sales in millions.

9.    Add a horizontal line at y-intercept=0.

10.   Write 2-3 sentences interpreting the plot answering the question “How has the sentiment of Taylor Swift’s albums have changed over time?”. Add a title, subtitle, and useful axis labels.

** Josh: The plot below shows that the mean sentiment of Taylor Swift's albums have become more negative over time. While I am unsure why this trend exists, I suspect it may be influenced by popular demand. **

```{r, fig.show = 'hold', results = 'hold', message = FALSE}
ts_lyrics.summary2 <- 
  ts_lyrics.mod.words %>%
  group_by(Album) %>%
  count(word, sort = TRUE) %>%
  inner_join(get_sentiments("afinn")) %>%
  summarize(mean_sentiment = (n %*% value) / sum(n)) %>%        # mean sentiment (weighted by word frequency)
  left_join(sales.mod, by = "Album") %>%
  filter(country == "US")

ts_lyrics.summary2 %>%
  ggplot(aes(x = released, y = mean_sentiment, color = fct_reorder(Album, released))) +
  geom_point(aes(size = sales)) +
  geom_text(aes(x = released, y = mean_sentiment - 0.06, label = sales), color = "black") +
  geom_hline(yintercept = 0) + 
  guides(size = "none") +
  labs(title = "Taylor Swift: Mean Sentiment by Album Release Date",
       subtitle = "Average lyric sentiment is more negative for newer compared to older albums. \nUS album sales (in million USD) are reported below each point. ",
       x = "Album Release Date",
       y = "Mean Sentiment",
       caption = "Created by Josh Stim using ggplot2") +
  theme_bw() +
  theme(text = element_text(family = "Times"),
        plot.title = element_text(size = 18)) +
  guides(color = guide_legend(title = "Album")) 
```

## Part 3. R Session Information

```{r}
options(width = 120)
sessionInfo()
```

